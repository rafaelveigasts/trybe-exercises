## Complexidade Logar√≠tmica

Agora, vamos entender o que √© a Complexidade Logar√≠tmica. Mas, antes disso, √© preciso deixar n√≠tido que, apesar do termo potencialmente assustador, a Complexidade Logar√≠tmica n√£o exige c√°lculos matem√°ticos complicados para ser entendida. üôÇ

Representado pela nota√ß√£o O(log n), um algoritmo logar√≠tmico tem uma altera√ß√£o na taxa de execu√ß√£o que, geralmente, reduz pela metade o tempo de finaliza√ß√£o das itera√ß√µes ao reduzir pela metade o tamanho do input a cada itera√ß√£o.

Vamos refletir sobre isso:

Suponha que temos um algoritmo cuja entrada n √© igual a 4, se tivermos um algoritmo O(log n) a ser executado com essa entrada, teremos que fazer apenas 2 opera√ß√µes para execut√°-lo, pois log‚ÇÇn (l√™-se: "log de n na base 2") √© igual a 2. Se a nossa entrada fosse o dobro, ou seja, 8 ter√≠amos que realizar apenas 3 opera√ß√µes para chegar ao fim da execu√ß√£o. Ao dobrar o valor da entrada novamente, com n igual a 16, ter√≠amos que realizar apenas 4 opera√ß√µes (log‚ÇÇn √© igual a 4) e assim sucessivamente.

Anota a√≠ üñä: O n√∫mero de opera√ß√µes para executar o algoritmo logar√≠tmico tem uma rela√ß√£o inversa ao tamanho da entrada: quanto maior ela √©, menor o n√∫mero de opera√ß√µes e, consequentemente, menor o tempo para a execu√ß√£o do algoritmo!

Voc√™ pode estar se perguntando: "Mas como √© poss√≠vel criar um algoritmo com essa Ordem de Complexidade?"ü§î

No exemplo a seguir, temos um algoritmo de busca bin√°ria que entenderemos em detalhes mais adiante. Por ora, basta compreender que esse algoritmo representa uma complexidade O(log n).

Suponha que vamos criar um algoritmo de lista telef√¥nica. Temos uma lista de nomes de tamanho n, ordenada em ordem alfab√©tica, e um nome x; devemos encontrar o n√∫mero de telefone da pessoa passada na entrada.

Suponha que vamos procurar pelo nome Tintim.Como faremos isso?

Buscar na p√°gina (ou posi√ß√£o) da lista que tenha nomes come√ßando com a letra T;
Escolher uma p√°gina aleat√≥ria da lista para abrir;
Percebemos que ca√≠mos na posi√ß√£o da letra M;
Como M < T, na ordem alfab√©tica, ent√£o, devemos avan√ßar algumas posi√ß√µes para encontrar o T;
Ent√£o, escolhemos uma p√°gina que est√° mais adiante;
Percebemos que ca√≠mos na posi√ß√£o da letra V;
Como V > T, na ordem alfab√©tica, ent√£o devemos voltar alguns posi√ß√µes;
Vamos repetimos esse processo at√© encontrarmos o nome desejado.

Haveria outra forma de fazer essa pesquisa na lista telef√¥nica? Sim! N√≥s poder√≠amos passar por cada p√°gina, da letra A at√© a letra T para encontrar Tintim. Por√©m, o n√∫mero de opera√ß√µes necess√°rias para realizar isso seria muito maior do que aquele que usamos no exemplo acima!

Perceba o seguinte: o nosso alfabeto tem 26 letras e a letra T est√° na posi√ß√£o 20 dele. Se segu√≠ssemos o algoritmo de busca sequencial, passando sequencialmente pelas letras de A √† T, ter√≠amos que realizar 20 opera√ß√µes para encontrar o que est√°vamos procurando. Mas, se us√°ssemos o algoritmo de busca bin√°ria, que criamos acima, poder√≠amos resolver facilmente o problema de encontrar a letra T utilizando menos da metade das opera√ß√µes que uma busca sequencial demanda. Ou seja, poder√≠amos facilmente encontrar a letra T na lista telef√¥nica com 10 ou menos passos, obtendo, assim, um algoritmo de complexidade O(log n) para resolver o problema.

Para entender melhor a diferen√ßa entre um algoritmo de busca bin√°ria, logar√≠tmico, com um de busca sequencial, que √© linear, observe o gif abaixo.

<img src ='binary-and-linear-search-animations.gif' />

Agora que j√° passamos pelo conceito de Complexidade Logar√≠tmica, vejamos o algoritmo de busca bin√°ria abaixo.

De olho na dicaüëÄ: √© altamente recomendado que voc√™ rode na sua m√°quina para entender melhor como funciona):

# A estrutura deve estar ordenada para que a busca bin√°ria funcione

def binary_search(numbers, target): # definir os √≠ndices
start = 0
end = len(numbers) - 1

    while start <= end: # os √≠ndices podem ser no m√°ximo iguais, o in√≠cio n√£o pode ultrapassar o fim
        mid = (start + end) // 2 # encontro o meio

        if numbers[mid] == target: # se o elemento do meio for o alvo, devolve a posi√ß√£o do meio
            return mid

        if target < numbers[mid]: # se o elemento for menor, atualiza o √≠nd√≠ce do fim
            end = mid - 1
        else: # caso contr√°rio, atualiza o √≠nd√≠ce do inicio
            start = mid + 1

    return -1 # N√£o encontrou? Retorna -1

numbers = [2, 3, 4, 10, 40]
target = 40

result = binary_search(numbers, target)
print(f"Elemento encontrado na posi√ß√£o: {result}")

Observe como, a cada itera√ß√£o, o algoritmo de busca bin√°ria corta o problema pela metade:

primeiro ele "corta" a lista em dois e pega o elemento do meio.

Depois ele "caminha" para o lado no elemento que procura esta e "corta" este lado novamente pela metade.

Anota a√≠ üñä: Quando cortamos a entrada pela metade, a cada itera√ß√£o, temos um padr√£o que segue a fun√ß√£o matem√°tica de logaritmo na base dois! Assim, nosso algoritmo √© O(log n).

Um logaritmo em base 2 representa o n√∫mero de vezes que um valor deve ser dividido pela metade para obter 1.

Dessa forma, sem precisarmos nos aprofundar na matem√°tica, conseguimos calcular a ordem de complexidade de um algoritmo deste tipo: Quando a entrada √© cortada pela metade a cada itera√ß√£o temos um comportamento logar√≠tmico!

Veja abaixo um gr√°fico que compara o tempo de execu√ß√£o de um algoritmo linear e um logar√≠tmico.

<img src = 'logaritmo-vs-linear.jpg' />

Agora, para fixar esse conceito, vamos fazer um exerc√≠cio!

Exerc√≠cios de Fixa√ß√£o

Exerc√≠cio 4: Imagine que voc√™ recebe dois arrays de tamanho igual, array1 e array2. Para cada elemento do array1, realize uma busca bin√°ria no array2. Mostre que a ordem de complexidade do algoritmo resultante √© O(n \* log n), ou O(n log n).

‚ö†Ô∏è Aviso: N√£o precisa implementar o c√≥digo aqui!
